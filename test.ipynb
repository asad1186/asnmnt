{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f760ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cbaf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.llm_client import OpenAIClient\n",
    "from app.agent import AIAgent\n",
    "from app.tools import retrieve_docs\n",
    "from app.memory import SessionMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ede8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "llm = OpenAIClient()\n",
    "memory = SessionMemory()\n",
    "tools = {\"retrieve_docs\": retrieve_docs}\n",
    "agent = AIAgent(llm, tools, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94faad75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Employees are entitled to 20 paid leave days per year.', 'sources': ['leave_policy.txt', 'remote_work_policy.txt']}\n"
     ]
    }
   ],
   "source": [
    "result = agent.decide_and_answer(\"how many days a person can take leave in a year\", session_id=\"abc123\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ff0b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of large language models (LLMs), \"hallucination\" refers to the phenomenon where the model generates information that is false, misleading, or not grounded in reality. This can occur when the model produces responses that sound plausible but are actually incorrect or fabricated. Hallucinations can arise due to various reasons, including:\n",
      "\n",
      "1. **Training Data Limitations**: The model may not have been trained on accurate or comprehensive data regarding a specific topic.\n",
      "2. **Inference Errors**: During the generation process, the model might make incorrect associations or extrapolations based on its training.\n",
      "3. **Ambiguity in Queries**: Vague or ambiguous questions can lead the model to generate responses that do not accurately reflect the intended meaning.\n",
      "\n",
      "Hallucinations are a known challenge in the deployment of LLMs and are an area of active research to improve the reliability and accuracy of these models.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841cdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run only once\n",
    "# from app.rag import create_faiss_index\n",
    "# create_faiss_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78ff933",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={'a':2324,\n",
    "   'b':563}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27dd57f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get('c', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2d93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
